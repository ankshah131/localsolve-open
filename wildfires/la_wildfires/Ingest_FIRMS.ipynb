{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNu+XJ66BjVDtE0JaLuzBoL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ankshah131/localsolve-open/blob/main/wildfires/la_wildfires/Ingest_FIRMS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's set your map key that was emailed to you. It should look something like 'abcdef1234567890abcdef1234567890'\n",
        "MAP_KEY = 'd62477789af77695549777c63ccf5c76'\n",
        "\n",
        "# now let's check how many transactions we have\n",
        "import pandas as pd\n",
        "url = 'https://firms.modaps.eosdis.nasa.gov/mapserver/mapkey_status/?MAP_KEY=' + MAP_KEY\n",
        "try:\n",
        "  df = pd.read_json(url,  typ='series')\n",
        "  display(df)\n",
        "except:\n",
        "  # possible error, wrong MAP_KEY value, check for extra quotes, missing letters\n",
        "  print (\"There is an issue with the query. \\nTry in your browser: %s\" % url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "tMUoe7vwKTqu",
        "outputId": "cb133de1-3d34-4024-df55-abfa96a1b7bf"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "transaction_limit             5000\n",
              "current_transactions             0\n",
              "transaction_interval    10 minutes\n",
              "dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>transaction_limit</th>\n",
              "      <td>5000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>current_transactions</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>transaction_interval</th>\n",
              "      <td>10 minutes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "from datetime import date\n",
        "import logging\n",
        "import os\n",
        "import time\n",
        "from tempfile import mkdtemp\n",
        "from typing import List, Tuple\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "import urllib\n",
        "import shapely\n",
        "from shapely.geometry import Polygon\n",
        "\n",
        "logging.basicConfig(\n",
        "    format='%(asctime)s %(levelname)-8s %(message)s',\n",
        "    level=logging.INFO,\n",
        "    datefmt='%Y-%m-%d %H:%M:%S')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "class Settings:\n",
        "    \"\"\"Class for storing config and global variables for this ingest script.\"\"\"\n",
        "    temp_dir: str = './Shapefiles/'\n",
        "    today = date.today()\n",
        "    output_shp_filename = 'FIRMS_' + str(today) + '.shp'\n",
        "    firms_wfs_url_prefix: str = 'https://firms.modaps.eosdis.nasa.gov/mapserver/wfs/<country>'\n",
        "    firms_wfs_url_suffix: str = '?SERVICE=WFS&REQUEST=GetFeature&VERSION=2.0.0&TYPENAME=ms:fires_<satellite>_24hrs&' + \\\n",
        "                                'STARTINDEX=0&COUNT=1000&SRSNAME=urn:ogc:def:crs:EPSG::4326&BBOX=-90,-180,90,180,urn:ogc:def:crs:EPSG::4326&outputformat=csv'\n",
        "\n",
        "    firms_wfs_request_sleep_secs: int = 5\n",
        "    firms_api_map_keys: str = 'd62477789af77695549777c63ccf5c76'\n",
        "\n",
        "\n",
        "config = Settings()\n",
        "\n",
        "\n",
        "def ingest(user_country):\n",
        "    \"\"\"Main function to get new active wildfire data and save it as a shapefile.\"\"\"\n",
        "    logger.info(\"Processing new FIRMS VIIRS Merged Ultra Real Time wildfire data for the last 24 hours\")\n",
        "    country = user_country\n",
        "    get_new_data(country)\n",
        "    logger.info(\"Done!\")\n",
        "    return\n",
        "\n",
        "\n",
        "def get_new_data(user_country):\n",
        "    \"\"\"Download the latest VIIRS active URT 24-hour fire data for the specified bounding box.\"\"\"\n",
        "    logger.info(\"Collecting newest VIIRS detections from the FIRMS WFS\")\n",
        "    region_sat_df_list = []\n",
        "    country = user_country\n",
        "\n",
        "    satellites = ['snpp', 'noaa20']\n",
        "\n",
        "    for satellite in satellites:\n",
        "        logger.info(f\"Downloading the last 24 hours of detections from {satellite}\")\n",
        "        for i in range(1, 6):  # Retry mechanism\n",
        "            try:\n",
        "                url = f\"{config.firms_wfs_url_prefix.replace('<country>',country)}/{config.firms_api_map_keys}/{config.firms_wfs_url_suffix.replace('<satellite>', satellite)}\"\n",
        "                region_sat_df = pd.read_csv(url)\n",
        "                break\n",
        "            except (urllib.error.HTTPError, urllib.error.URLError, ConnectionError) as e:\n",
        "                if i == 5:\n",
        "                    logger.exception(\"Unable to retrieve newest data from the FIRMS API\")\n",
        "                    raise e\n",
        "                else:\n",
        "                    logger.warning(f\"Retrying {i}/5 after failure to retrieve data from FIRMS API\")\n",
        "                    time.sleep(30)\n",
        "        region_sat_df_list.append(region_sat_df)\n",
        "        time.sleep(config.firms_wfs_request_sleep_secs)\n",
        "\n",
        "    new_fires_df = pd.concat(region_sat_df_list, ignore_index=True)\n",
        "    logger.info(f\"Number of detections pre-deduplication: {len(new_fires_df)}\")\n",
        "    new_fires_df.drop_duplicates(inplace=True, ignore_index=True)\n",
        "    logger.info(f\"Number of detections post-deduplication: {len(new_fires_df)}\")\n",
        "\n",
        "    logger.info(\"Processing WFS data and writing to shapefile\")\n",
        "    new_fires_df.columns = map(str.upper, new_fires_df.columns)\n",
        "    new_fires_df['ACQ_TIME'] = new_fires_df['ACQ_TIME'].astype(int).astype(str).str.zfill(4)\n",
        "    new_fires_df['ACQ_DATE'] = new_fires_df['ACQ_DATE'].astype(str)\n",
        "    confidence_value_map_dict = {\n",
        "        'h': 'high',\n",
        "        'n': 'nominal',\n",
        "        'l': 'low'\n",
        "    }\n",
        "    new_fires_df['CONFIDENCE'] = new_fires_df['CONFIDENCE'].map(confidence_value_map_dict)\n",
        "    new_fires_df['ACQ_DATETIME'] = new_fires_df['ACQ_DATETIME'].apply(str)\n",
        "    new_fires_df.ACQ_DATETIME = new_fires_df.ACQ_DATETIME.str.replace(\"\\\\+00\", 'Z', regex=True)\n",
        "    new_fires_df.ACQ_DATETIME = new_fires_df.ACQ_DATETIME.str.replace(' ', 'T')\n",
        "    new_fires_df.ACQ_DATETIME = new_fires_df.ACQ_DATETIME.str.replace('/', '-')\n",
        "    new_fires_df.rename(columns={'ACQ_DATETIME': 'ACQ_DT',\n",
        "                                 'BRIGHTNESS_2': 'BRIGHT_2'},\n",
        "                        inplace=True)\n",
        "    if 'UNNAMED: 1' in new_fires_df.columns:\n",
        "        columns_to_drop = ['UNNAMED: 1', 'WKT']\n",
        "    else:\n",
        "        columns_to_drop = ['WKT']\n",
        "    new_fires_df.drop(columns=columns_to_drop, inplace=True)\n",
        "    new_fires_gdf = gpd.GeoDataFrame(new_fires_df,\n",
        "                                     geometry=gpd.points_from_xy(new_fires_df.LONGITUDE, new_fires_df.LATITUDE))\n",
        "\n",
        "    # Create a bounding box polygon\n",
        "    bbox = Polygon([(-118.951721, 32.75004), (-118.951721, 34.823302), (-117.646374, 34.823302), (-117.646374, 32.75004)])\n",
        "\n",
        "    # Find points within the bounding box\n",
        "    points_in_bbox = new_fires_gdf[new_fires_gdf.within(bbox)]\n",
        "\n",
        "    points_in_bbox.crs = 'EPSG:4326'\n",
        "    output_file_path = os.path.join(config.temp_dir, config.output_shp_filename)\n",
        "    points_in_bbox.to_file(filename=output_file_path)\n",
        "    logger.info(f\"Shapefile written to: {output_file_path}\")\n",
        "\n",
        "    return\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # User-provided bounding box (example: -90, -180, 90, 180)\n",
        "    country = 'USA_contiguous_and_Hawaii'  # Example for the contiguous USA\n",
        "    ingest(country)\n"
      ],
      "metadata": {
        "id": "3suBPKWdM05-"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lT0GUtjy-gvF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}